{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating the range estimates #\n",
    "\n",
    "In [one of the previous notebooks](agile_estimation_2.ipynb)we have established a statistical model for predicting the actual project time and cost based on the estimates. We discussed that we can fit the estimates (both for the Agile and Waterfall projects) to a Log-Normal distribution, which guarantees the positive support. Using statistical approach to estimation allows us to give prediction with a required confidence level, and also project monetary benefits, costs and risk, as we discussed in [another notebook](agile_estimation_3.ipynb).\n",
    "\n",
    "One thing I was asked is how the model generalizes for the case when an estimate is given as a range. Indeed, this is what everybody taught us: do not give a single number, but range. One approach is to continue to use our statistical model, and feed it a number in the middle, the mean of the two values. \n",
    "\n",
    "$$x = \\frac{high+low}{2}$$\n",
    "\n",
    "That way the model can be used without modifications.\n",
    "\n",
    "There are two problems with this approach: \n",
    "1. Taking a mean of high and low is arbitrary. It reduces the information given by half. It would be better to have an algorithm learn where we need to set the variable x within the interval between low and high boundaries\n",
    "2. By giving us a range of data, a developer is trying to convey to us a very important information: a degree of uncertainty in the estimates. A correct model should use that information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the process, we will take natural logarithm of all the estimates and the actuals. Since we model estimates using log-normal distribution, our new variables `y`, `l`, `h` will be logarithms of the actual number of days, low and high estimates respectively. In this case we can use Normal distribution!\n",
    "We will model `y` using linear regression:\n",
    "$$ y = \\theta_h h + \\theta_l l $$\n",
    "\n",
    "In case where $\\theta_h$ and $\\theta_l$ are equal, we get exactly the same problem as we discussed [earlier](agile_estimation_2.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood function for a single piece of data in this case can be written as follows (following [this](https://en.wikipedia.org/wiki/Bayesian_linear_regression)). \n",
    "\n",
    "$$ \\rho(y|h,l,\\theta_h, \\theta_l, \\sigma) \\propto \\frac{1}{\\sigma} \\exp(-\\frac{1}{2\\sigma^2}(y - \\theta_h h - \\theta_l l)^2 )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, by giving a range, the developer wanted to communicate to us the uncertainty of the estimate. We should include this uncertainty in our estimate of $\\sigma$. Intuitively the range is proportional to the standard deviation, and we can learn the coefficient by modeling $\\sigma$ as:\n",
    "$$\\sigma = \\sigma_0 (1 + \\zeta^2 (h-l))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we also use precision parameter $\\tau$ in place of $\\sigma_0$:\n",
    "$$\\tau = \\frac{1}{\\sigma^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then our likelihood function will be:\n",
    "$$ \\rho(y|h,l,\\theta_h, \\theta_l, \\tau, \\zeta) \\propto \\frac{\\sqrt{\\tau}}{1 + \\zeta^2 (h-l)} \\exp(-\\frac{\\tau}{2(1 + \\zeta^2 (h-l))^2}(y - \\theta_h h - \\theta_l l)^2 )$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The priors for $\\tau$ and $\\theta$ are traditionally Gamma and Normal distribution respectively:\n",
    "\n",
    "$$\\rho(\\tau) \\propto \\tau^{\\alpha-1}e^{-\\beta \\tau}$$\n",
    "\n",
    "$$\\rho(\\theta|\\tau) \\propto \\tau \\exp(-\\frac{\\tau \\lambda}{2}(\\theta_h^2+\\theta_l^2))$$\n",
    "\n",
    "Here $\\alpha$, $\\beta$, $\\lambda$ are hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of prior for $\\zeta$ is more difficult. None of the conjugate priors exist for the kind of likelihood function we have chosen. For now we can select the normal distribution. Zero mean of this distribution means that a priori we don't trust the ranges (we know that many consultants the range is always 20% and does not convey any information). High mean of the prior distribution means that we pay more attention to the estimated degree of uncertainty.\n",
    "\n",
    "For simplicity  we set the mean to zero.\n",
    "\n",
    "$$\\rho(\\zeta) \\propto \\sqrt{\\tau} \\exp(-\\frac{\\tau \\lambda_\\zeta}{2}\\zeta^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative log-posterior function is:\n",
    "$$ \\mathscr{L}(\\theta_h, \\theta_l,\\zeta, \\tau) = \\sum_{i=0}^{N-1}[\\log(1 + \\zeta^2 (h^{(i)}-l^{(i)})) +\n",
    "\\frac{\\tau}{2(1 + \\zeta^2 (h^{(i)}-l^{(i)}))^2}(y - \\theta_h h^{(i)} - \\theta_l h^{(i)})^2 ]\n",
    "- \\frac{N+1+2\\alpha}{2}\\log{\\tau} + \\beta \\tau + \\frac{\\tau \\lambda}{2}(\\theta_h^2+\\theta_l^2))\n",
    "+ \\frac{\\tau \\lambda_\\zeta}{2}\\zeta^2\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will find parameters, corresponding to the maximum posterior. And to avoid making errors in differentiating, we will use TensorFlow. We will follow [this example](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/examples/get_started/regression/custom_regression.py) to build our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here represent the estimated and actual number of days. We see that the developer liked to add 25% to his estimate as a buffer.However for some of the stories he added more buffer, perhaps, to indicate more uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    low  high  actual\n",
       "0     4     5      17\n",
       "1    14    18       8\n",
       "2     4     5       5\n",
       "3     3     4       3\n",
       "4     4     5       5\n",
       "5     3     7       4\n",
       "6     4     5       9\n",
       "7     9    10       9\n",
       "8     6     8       4\n",
       "9    27    30      27\n",
       "10   20    25      16\n",
       "11   23    29      15\n",
       "12   11    14       7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=1389\n",
    "tf.reset_default_graph()\n",
    "task_data = pd.DataFrame({'low':[4,14,4,3,4,3,4,9,6,27,20,23,11],\n",
    "                          'high':[5,18,5,4,5,7,5,10,8,30,25,29,14],\n",
    "                          'actual':[17,8,5,3,5,4,9,9,4,27,16,15,7,]})\n",
    "task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209f3cb9080>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(11.7, 8.27))\n",
    "task_data['story_id'] = task_data.index\n",
    "data_for_plot = pd.melt(task_data, id_vars=\"story_id\", var_name=\"type\", value_name=\"days\")\n",
    "task_data.drop(columns=['story_id'], inplace=True)\n",
    "sns.barplot(x='story_id', y='days', hue='type', data=data_for_plot,ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining variables, we substitute $\\tau$ for another variable $\\rho$:\n",
    "$$ \\tau = \\rho^2 $$\n",
    "This is to avoid the optimizer selecting negative $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the log of data\n",
    "log_data = np.log(task_data.values)\n",
    "N = log_data.shape[0]\n",
    "\n",
    "#Defining variables\n",
    "theta_h = tf.Variable(name='theta_h', initial_value=0.5)\n",
    "theta_l = tf.Variable(name='theta_l', initial_value=0.5)\n",
    "zeta = tf.Variable(name='zeta', initial_value=0.01)\n",
    "rho = tf.Variable(name='rho', initial_value=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't want to tune too many hyperparameters, we will set $\\alpha$ and $\\beta$ to one. Both $\\lambda$ parameters act as regularization parameters, so we will have to tune them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the hyperparameters\n",
    "alpha = tf.constant(name='alpha', value=1.0)\n",
    "beta = tf.constant(name='beta', value=1.0)\n",
    "lambda1 = tf.constant(name='lambda1', value=1e-4)\n",
    "lambda2 = tf.constant(name='lambda2', value=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(l, h, y):\n",
    "    return tf.log(1+zeta**2*(h-l)) + \\\n",
    "        rho**2/2/(1+zeta**2*(h-l))**2 * (y - theta_l*l - theta_h*h)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cummulative_loss = tf.reduce_sum(list(np.apply_along_axis(lambda x: loss(*x), axis=1, arr=log_data )))\n",
    "cost = cummulative_loss - (N+1-2*alpha)/2*tf.log(rho**2) + beta*rho**2 + \\\n",
    "rho**2*lambda1/2*(theta_h**2+theta_l**2) + rho**2*lambda2/2*zeta**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost = 55.26268\n",
      "Parameters: 0.5, 0.5, 0.009999999776482582, 0.009999999776482582\n",
      "Epoch 10000 Cost = 6.5892615\n",
      "Parameters: 0.24855799973011017, 0.6630115509033203, 0.6332486271858215, 1.1534561276317736e-35\n",
      "Epoch 20000 Cost = 1.39517\n",
      "Parameters: 0.2485545128583908, 0.6630078554153442, 1.3754394054412842, 1.1534561276317736e-35\n",
      "Epoch 30000 Cost = 1.3396643\n",
      "Parameters: 0.24855604767799377, 0.6630094647407532, 1.4745615720748901, 1.1534561276317736e-35\n",
      "Epoch 40000 Cost = 1.3396641\n",
      "Parameters: 0.24855272471904755, 0.6630063056945801, 1.4745622873306274, 1.1534561276317736e-35\n",
      "Epoch 50000 Cost = 1.3396646\n",
      "Parameters: 0.2485586702823639, 0.6630119681358337, 1.4745632410049438, 1.1534561276317736e-35\n",
      "Epoch 60000 Cost = 1.3396648\n",
      "Parameters: 0.2485581487417221, 0.6630115509033203, 1.4745649099349976, 1.1534561276317736e-35\n",
      "Epoch 70000 Cost = 1.3396643\n",
      "Parameters: 0.2485586702823639, 0.6630122065544128, 1.4745644330978394, 1.1534561276317736e-35\n",
      "Epoch 80000 Cost = 1.3396643\n",
      "Parameters: 0.24855820834636688, 0.6630116701126099, 1.4745631217956543, 1.1534561276317736e-35\n",
      "Epoch 90000 Cost = 1.3396646\n",
      "Parameters: 0.248562291264534, 0.663015604019165, 1.474563717842102, 1.1534561276317736e-35\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "init = tf.global_variables_initializer()\n",
    "n_epochs = int(1e5)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1e4 == 0:\n",
    "            print(\"Epoch\", epoch, \"Cost =\", cost.eval())\n",
    "            print(f'Parameters: {theta_l.eval()}, {theta_h.eval()}, {rho.eval()}, {zeta.eval()}')\n",
    "        sess.run(train_op)\n",
    "    best_theta_l = theta_l.eval()\n",
    "    best_theta_h = theta_h.eval()\n",
    "    best_sigma = 1/math.sqrt(rho.eval())    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is interesting here is that $\\zeta$ is zero. This means that we cannot trust the estimation of uncertainty that the developers give us. This also means that we can just use log-normal distribution around the mean specified by the learned parameters $\\theta_l$ and $\\theta_h$. Let's say, the same developer estimated a new task to take 10-15 days. Plugging it into the formulas we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.67385532327305"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = best_theta_l*math.log(10)+best_theta_h*math.log(15)\n",
    "most_likely_prediction = math.exp(mu)    \n",
    "most_likely_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the 95% confidence, by plugging the values directly into log-normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence: 41.3614192940211\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import lognorm\n",
    "distribution = lognorm(s=best_sigma, scale=most_likely_prediction, loc=0)\n",
    "print(f'95% confidence: {distribution.ppf(0.95)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, if we want 95% of confidence, we have to give an estimate of 41 days, instead of 11 days for 50% confidence. This is very easily explained if you see that in the past the developer did not do a very good job estimating the tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
