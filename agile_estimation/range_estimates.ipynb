{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating the range estimates #\n",
    "\n",
    "In [one of the previous notebooks](agile_estimation_2.ipynb)we have established a statistical model for predicting the actual project time and cost based on the estimates. We discussed that we can fit the estimates (both for the Agile and Waterfall projects) to a Log-Normal distribution, which guarantees the positive support. Using statistical approach to estimation allows us to give prediction with a required confidence level, and also project monetary benefits, costs and risk, as we discussed in [another notebook](agile_estimation_3.ipynb).\n",
    "\n",
    "One thing I was asked is how the model generalizes for the case when an estimate is given as a range. Indeed, this is what everybody taught us: do not give a single number, but range. One approach is to continue to use our statistical model, and feed it a number in the middle, the mean of the two values. \n",
    "\n",
    "$$x = \\frac{high+low}{2}$$\n",
    "\n",
    "That way the model can be used without modifications.\n",
    "\n",
    "There are two problems with this approach: \n",
    "1. Taking a mean of high and low is arbitrary. It reduces the information given by half. It would be better to have an algorithm learn where we need to set the variable x within the interval between low and high boundaries\n",
    "2. By giving us a range of data, a developer is trying to convey to us a very important information: a degree of uncertainty in the estimates. A correct model should use that information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the process, we will take natural logarithm of all the estimates and the actuals. Since we model estimates using log-normal distribution, our new variables `y`, `l`, `h` will be logarithms of the actual number of days, low and high estimates respectively. In this case we can use Normal distribution!\n",
    "We will model `y` using linear regression:\n",
    "$$ y = \\theta_h h + \\theta_l l $$\n",
    "\n",
    "In case where $\\theta_h$ and $\\theta_l$ are equal, we get exactly the same problem as we discussed [earlier](agile_estimation_2.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood function for a single piece of data in this case can be written as follows (following [this](https://en.wikipedia.org/wiki/Bayesian_linear_regression)). \n",
    "\n",
    "$$ \\rho(y|h,l,\\theta_h, \\theta_l, \\sigma) \\propto \\frac{1}{\\sigma} \\exp(-\\frac{1}{2\\sigma^2}(y - \\theta_h h - \\theta_l l)^2 )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, by giving a range, the developer wanted to communicate to us the uncertainty of the estimate. We should include this uncertainty in our estimate of $\\sigma$. Intuitively the range is proportional to the standard deviation, and we can learn the coefficient by modeling $\\sigma$ as:\n",
    "$$\\sigma = \\sigma_0 (1 + \\zeta^2 (h-l))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we also use precision parameter $\\tau$ in place of $\\sigma_0$:\n",
    "$$\\tau = \\frac{1}{\\sigma^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then our likelihood function will be:\n",
    "$$ \\rho(y|h,l,\\theta_h, \\theta_l, \\tau, \\zeta) \\propto \\frac{\\sqrt{\\tau}}{1 + \\zeta^2 (h-l)} \\exp(-\\frac{\\tau}{2(1 + \\zeta^2 (h-l))^2}(y - \\theta_h h - \\theta_l l)^2 )$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The priors for $\\tau$ and $\\theta$ are traditionally Gamma and Normal distribution respectively:\n",
    "\n",
    "$$\\rho(\\tau) \\propto \\tau^{\\alpha-1}e^{-\\beta \\tau}$$\n",
    "\n",
    "$$\\rho(\\theta|\\tau) \\propto \\tau \\exp(-\\frac{\\tau \\lambda}{2}(\\theta_h^2+\\theta_l^2))$$\n",
    "\n",
    "Here $\\alpha$, $\\beta$, $\\lambda$ are hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of prior for $\\zeta$ is more difficult. None of the conjugate priors exist for the kind of likelihood function we have chosen. For now we can select the normal distribution. Zero mean of this distribution means that a priori we don't trust the ranges (we know that many consultants the range is always 20% and does not convey any information). High mean of the prior distribution means that we pay more attention to the estimated degree of uncertainty.\n",
    "\n",
    "For simplicity  we set the mean to zero.\n",
    "\n",
    "$$\\rho(\\zeta) \\propto \\sqrt{\\tau} \\exp(-\\frac{\\tau \\lambda_\\zeta}{2}\\zeta^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative log-posterior function is:\n",
    "$$ \\mathscr{L}(\\theta_h, \\theta_l,\\zeta, \\tau) = \\sum_{i=0}^{N-1}[\\log(1 + \\zeta^2 (h^{(i)}-l^{(i)})) +\n",
    "\\frac{\\tau}{2(1 + \\zeta^2 (h^{(i)}-l^{(i)}))^2}(y - \\theta_h h^{(i)} - \\theta_l h^{(i)})^2 ]\n",
    "- \\frac{N+1+2\\alpha}{2}\\log{\\tau} + \\beta \\tau + \\frac{\\tau \\lambda}{2}(\\theta_h^2+\\theta_l^2))\n",
    "+ \\frac{\\tau \\lambda_\\zeta}{2}\\zeta^2\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will find parameters, corresponding to the maximum posterior. And to avoid making errors in differentiating, we will use TensorFlow. We will follow [this example](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/examples/get_started/regression/custom_regression.py) to build our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1389\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
