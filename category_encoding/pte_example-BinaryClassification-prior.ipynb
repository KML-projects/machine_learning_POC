{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pathlib\n",
    "current = pathlib.Path(os.getcwd())\n",
    "base = current.parent.parent\n",
    "catenc = base.joinpath('categorical-encoding')\n",
    "sys.path.append(str(catenc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification problem\n",
    "\n",
    "For Binary classifier we will work with the example 10.2 of T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical Learning Ed. 2\", Springer, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "X_h, y_h = make_hastie_10_2(random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now convert the last column to the categorical\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "disczr1 = KBinsDiscretizer(n_bins=20, encode='ordinal', strategy='uniform')\n",
    "cat_column1 = disczr1.fit_transform(X_h[:,-1].reshape(-1, 1)) * 193 % 20 #We want to break the monotonicity\n",
    "disczr2 = KBinsDiscretizer(n_bins=15, encode='ordinal', strategy='uniform')\n",
    "cat_column2 = disczr2.fit_transform(X_h[:,-2].reshape(-1, 1)) * 173 % 20 #We want to break the monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.372591</td>\n",
       "      <td>-2.090973</td>\n",
       "      <td>1.708557</td>\n",
       "      <td>-0.275200</td>\n",
       "      <td>-0.398902</td>\n",
       "      <td>1.024470</td>\n",
       "      <td>-0.765034</td>\n",
       "      <td>-0.189323</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469180</td>\n",
       "      <td>1.482655</td>\n",
       "      <td>0.573892</td>\n",
       "      <td>1.517456</td>\n",
       "      <td>-0.036815</td>\n",
       "      <td>-0.188150</td>\n",
       "      <td>-0.654887</td>\n",
       "      <td>1.071954</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405521</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>-1.036971</td>\n",
       "      <td>-0.901881</td>\n",
       "      <td>-2.526267</td>\n",
       "      <td>0.429153</td>\n",
       "      <td>-1.177047</td>\n",
       "      <td>-0.425995</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0 -1.372591 -2.090973  1.708557 -0.275200 -0.398902  1.024470 -0.765034   \n",
       "1  0.469180  1.482655  0.573892  1.517456 -0.036815 -0.188150 -0.654887   \n",
       "2 -0.405521  0.231156 -1.036971 -0.901881 -2.526267  0.429153 -1.177047   \n",
       "\n",
       "      col_7  cat1  cat2  \n",
       "0 -0.189323   4.0  11.0  \n",
       "1  1.071954  17.0  18.0  \n",
       "2 -0.425995  17.0  11.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = pd.DataFrame(X_h[:, 0:-2], columns=[f'col_{i}' for i in range(8)])\n",
    "predictors['cat1'] = cat_column1\n",
    "predictors['cat2'] = cat_column2\n",
    "#predictors['cat1_orig'] = cat_column1\n",
    "#predictors['cat2_orig'] = cat_column2\n",
    "predictors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  1.0\n",
      "Test accuracy:  0.8508333333333333\n",
      "AUC:  0.9281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=40, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))\n",
    "print('AUC: ', roc_auc_score(y_test, preds).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning: optimizing for AUC\n",
    "estimators: 400\n",
    "max depth:\n",
    "* 15 | 0.9334 \n",
    "* 17 | 0.9384\n",
    "* 19 | 0.9398\n",
    "* 21 | 0.9415\n",
    "* 25 | 0.9449\n",
    "* 30 | 0.947\n",
    "* 10 | 0.9476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  1.0\n",
      "Test accuracy:  0.8929166666666667\n",
      "AUC:  0.962\n"
     ]
    }
   ],
   "source": [
    "#Now we will try to do target encoding\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "loo = LeaveOneOutEncoder(cols=['cat1', 'cat2'], random_state=2834)\n",
    "loo.fit(pd.DataFrame(X_train, columns=predictors.columns), y_train)\n",
    "X_train = loo.transform(pd.DataFrame(X_train, columns=predictors.columns))\n",
    "X_test = loo.transform(pd.DataFrame(X_test, columns=predictors.columns))\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=40, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))\n",
    "print('AUC: ', roc_auc_score(y_test, preds).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning: optimizing for AUC\n",
    "estimators: 400\n",
    "max depth:\n",
    "* 17 | 0.9545\n",
    "* 20 | 0.956\n",
    "* 30 | 0.96\n",
    "* 40 | 0.9601\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, Now we will try to use the probabilistic target encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "from category_encoders.posterior_imputation_bc import PosteriorImputationEncoderBC \n",
    "\n",
    "pte = PosteriorImputationEncoderBC(cols=['cat1', 'cat2'], n_draws=25, random_state=2834, prior_samples_ratio=0.5)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "pte.fit(X_train, y_train)\n",
    "X_train = pte.transform(X_train)\n",
    "X_test = pte.transform(X_test)\n",
    "y_train = pte.expand_y(y_train)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=40, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "preds = pte.average_y(preds)\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))\n",
    "print('AUC: ', roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "We really should use cross-validation to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the target encoding model\n",
    "\n",
    "First we will train a model using target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "loo = LeaveOneOutEncoder(cols=['cat1', 'cat2'], sigma=0.05, random_state=2834)\n",
    "rf = RandomForestClassifier(n_estimators=400, max_depth=30, max_features=1, min_samples_leaf=1,\n",
    "                            random_state=2834, n_jobs=-1) \n",
    "clf = make_pipeline(loo, rf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation results:\n",
    "* max_depth=40: Accuracy: 0.67 (+/- 0.03)\n",
    "* max_depth=30: Accuracy: 0.68 (+/- 0.03)\n",
    "* max_depth=20: Accuracy: 0.67 (+/- 0.03)\n",
    "* max_depth=25: Accuracy: 0.67 (+/- 0.03)\n",
    "* max_depth=35: Accuracy: 0.67 (+/- 0.03)\n",
    "* max_depth=30, max_features=3: Accuracy: 0.67 (+/- 0.03)\n",
    "* max_depth=30, max_features=5: Accuracy: 0.58 (+/- 0.02)\n",
    "* max_depth=30, max_features=2: Accuracy: 0.77 (+/- 0.02)\n",
    "* max_depth=30, max_features=1: Accuracy: 0.87 (+/- 0.02)\n",
    "* max_depth=30, max_features=1, min_samples_leaf=3: Accuracy: 0.88 (+/- 0.02)\n",
    "* max_depth=30, max_features=1, min_samples_leaf=4: Accuracy: 0.87 (+/- 0.03)\n",
    "\n",
    "* max_depth=30, sigma=0.05: Accuracy: 0.89 (+/- 0.02)\n",
    "* max_depth=30, sigma=0.1: Accuracy: 0.89 (+/- 0.02)\n",
    "* max_depth=30, sigma=0.2: Accuracy: 0.89 (+/- 0.02)\n",
    "* max_depth=30, sigma=0.3: Accuracy: 0.87 (+/- 0.03)\n",
    "* max_depth=30, sigma=0.2, max_features=1: Accuracy: 0.89 (+/- 0.02)\n",
    "* max_depth=30, sigma=0.2, max_features=2: Accuracy: 0.87 (+/- 0.03)\n",
    "* max_depth=30, sigma=0.2, max_features=1, min_samples_leaf=3: Accuracy: 0.88 (+/- 0.02)\n",
    "* max_depth=30, sigma=0.2, max_features=1, min_samples_leaf=2: Accuracy: 0.88 (+/- 0.02)\n",
    "* max_depth=30, sigma=0.05, max_features=1, min_samples_leaf=1: Accuracy: 0.91 (+/- 0.01)\n",
    "\n",
    "\n",
    "\n",
    "**Optimal parameters**: sigma=0.05, max_depth=30, max_features=1, min_samples_leaf=1\n",
    "\n",
    "**Accuracy**: 0.91 (+/- 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9029166666666667\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "test_predict = clf.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the probabilistic encoder\n",
    "\n",
    "First we create a class that makes it easier for us to run sklearn cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class EncoderWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, encoder, classifier):\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.encoder.fit(X, y)\n",
    "        X_transformed = self.encoder.transform(X)\n",
    "        y_transformed = self.encoder.expand_y(y)\n",
    "        self.classifier.fit(X_transformed, y_transformed)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_transformed = self.encoder.transform(X)\n",
    "        preds = self.classifier.predict_proba(X_transformed)[:,1]\n",
    "        return self.encoder.average_y(preds)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).round()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90 (+/- 0.01)\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pte = PosteriorImputationEncoderBC(cols=['cat1', 'cat2'], n_draws=5, random_state=2834, prior_samples_ratio=0)\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=30, max_features=1, \n",
    "                               random_state=2834, n_jobs=-1) \n",
    "wrapper_model = EncoderWrapper(pte, model)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "\n",
    "scores = cross_val_score(wrapper_model, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation results:\n",
    "* Below are n_draws = 25\n",
    "* max_depth=40: Accuracy: 0.86 (+/- 0.03)\n",
    "* max_depth=30, prior_samples_ratio=0.5: Accuracy: 0.86 (+/- 0.03)\n",
    "* max_depth=30, prior_samples_ratio=0.1: Accuracy: 0.86 (+/- 0.02)\n",
    "* max_depth=30, prior_samples_ratio=0.01: Accuracy: 0.87 (+/- 0.01)\n",
    "* max_depth=30, prior_samples_ratio=0: Accuracy: 0.88 (+/- 0.01)\n",
    "* n_draws = 5, prior_samples_ratio=0, max_depth=30: Accuracy: 0.89 (+/- 0.01)\n",
    "* n_draws = 5, prior_samples_ratio=0, max_depth=30, max_features=1: Accuracy: 0.90 (+/- 0.01)\n",
    "\n",
    "**The best parameters**: n_draws = 5, prior_samples_ratio=0, max_depth=30, max_features=1\n",
    "**Accuracy**: 0.90 (+/- 0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8954166666666666\n"
     ]
    }
   ],
   "source": [
    "wrapper_model.fit(X_train, y_train)\n",
    "test_predict = wrapper_model.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy is again worse than for the target encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
