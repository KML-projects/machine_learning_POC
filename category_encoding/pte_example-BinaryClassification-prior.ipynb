{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pathlib\n",
    "current = pathlib.Path(os.getcwd())\n",
    "base = current.parent.parent\n",
    "catenc = base.joinpath('categorical-encoding')\n",
    "sys.path.append(str(catenc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification problem\n",
    "\n",
    "For Binary classifier we will work with the example 10.2 of T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical Learning Ed. 2\", Springer, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "X_h, y_h = make_hastie_10_2(random_state=2834)\n",
    "X_h = X_h.astype('float16')\n",
    "y_h[y_h==-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now convert the last column to the categorical\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "disczr1 = KBinsDiscretizer(n_bins=20, encode='ordinal', strategy='uniform')\n",
    "cat_column1 = disczr1.fit_transform(X_h[:,-1].reshape(-1, 1)) * 193 % 20 #We want to break the monotonicity\n",
    "disczr2 = KBinsDiscretizer(n_bins=15, encode='ordinal', strategy='uniform')\n",
    "cat_column2 = disczr2.fit_transform(X_h[:,-2].reshape(-1, 1)) * 173 % 20 #We want to break the monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.373047</td>\n",
       "      <td>-2.091797</td>\n",
       "      <td>1.708984</td>\n",
       "      <td>-0.275146</td>\n",
       "      <td>-0.398926</td>\n",
       "      <td>1.024414</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>-0.189331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469238</td>\n",
       "      <td>1.482422</td>\n",
       "      <td>0.573730</td>\n",
       "      <td>1.517578</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>-0.188110</td>\n",
       "      <td>-0.654785</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405518</td>\n",
       "      <td>0.231201</td>\n",
       "      <td>-1.037109</td>\n",
       "      <td>-0.901855</td>\n",
       "      <td>-2.525391</td>\n",
       "      <td>0.429199</td>\n",
       "      <td>-1.176758</td>\n",
       "      <td>-0.426025</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0 -1.373047 -2.091797  1.708984 -0.275146 -0.398926  1.024414 -0.765137   \n",
       "1  0.469238  1.482422  0.573730  1.517578 -0.036804 -0.188110 -0.654785   \n",
       "2 -0.405518  0.231201 -1.037109 -0.901855 -2.525391  0.429199 -1.176758   \n",
       "\n",
       "      col_7  cat1  cat2  \n",
       "0 -0.189331   4.0  11.0  \n",
       "1  1.072266  17.0  18.0  \n",
       "2 -0.426025  17.0  11.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = pd.DataFrame(X_h[:, 0:-2], columns=[f'col_{i}' for i in range(8)])\n",
    "predictors['cat1'] = cat_column1\n",
    "predictors['cat2'] = cat_column2\n",
    "#predictors['cat1_orig'] = cat_column1\n",
    "#predictors['cat2_orig'] = cat_column2\n",
    "predictors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  1.0\n",
      "Test accuracy:  0.84875\n",
      "AUC:  0.9255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=40, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))\n",
    "print('AUC: ', roc_auc_score(y_test, preds).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning: optimizing for AUC\n",
    "estimators: 400\n",
    "max depth:\n",
    "* 15 | 0.9334 \n",
    "* 17 | 0.9384\n",
    "* 19 | 0.9398\n",
    "* 21 | 0.9415\n",
    "* 25 | 0.9449\n",
    "* 30 | 0.947\n",
    "* 10 | 0.9476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "We really should use cross-validation to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the target encoding model\n",
    "\n",
    "First we will train a model using target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.898):\n",
      "{'loo__sigma': 0.01, 'rf__max_depth': 20, 'rf__max_features': 1, 'rf__min_samples_leaf': 2}\n",
      "Test accuracy:  0.89875\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "\n",
    "loo = LeaveOneOutEncoder(cols=['cat1', 'cat2'], sigma=0.05, random_state=2834)\n",
    "rf = RandomForestClassifier(n_estimators=400, max_depth=30, max_features=1, min_samples_leaf=1,\n",
    "                            random_state=2834, n_jobs=-1) \n",
    "pipe = Pipeline(steps=[('loo',loo), ('rf',rf)])\n",
    "\n",
    "param_grid = {\n",
    "    'loo__sigma': [0.01, 0.05],\n",
    "    'rf__max_depth': [15,20],\n",
    "    'rf__max_features' : [1,2],\n",
    "    'rf__min_samples_leaf': [2,3]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1,)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "test_predict = search.best_estimator_.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the probabilistic encoder\n",
    "\n",
    "First we create a class that makes it easier for us to run sklearn cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.pte_utils import EncoderWrapper\n",
    "from category_encoders.posterior_imputation_bc import PosteriorImputationEncoderBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.894):\n",
      "{'classifier__max_depth': 30, 'classifier__max_features': 1, 'classifier__min_samples_leaf': 3, 'encoder__n_draws': 3, 'encoder__prior_samples_ratio': 0.0001}\n",
      "Test accuracy:  0.89\n",
      "Wall time: 25min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pte = PosteriorImputationEncoderBC(cols=['cat1', 'cat2'], random_state=2834)\n",
    "model = RandomForestClassifier(n_estimators=400, random_state=2834, n_jobs=-1) \n",
    "wrapper_model = EncoderWrapper(pte, model)\n",
    "\n",
    "param_grid = {\n",
    "    'encoder__n_draws': [3,4],\n",
    "    'encoder__prior_samples_ratio': [1E-4, 1E-3],\n",
    "    'classifier__max_depth': [30,40],\n",
    "    'classifier__max_features' : [1,2],\n",
    "    'classifier__min_samples_leaf': [3,4]\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "\n",
    "search = GridSearchCV(wrapper_model, param_grid, cv=5, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "test_predict = search.best_estimator_.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, test_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
