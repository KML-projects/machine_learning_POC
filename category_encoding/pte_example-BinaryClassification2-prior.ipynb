{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pathlib\n",
    "current = pathlib.Path(os.getcwd())\n",
    "base = current.parent.parent\n",
    "catenc = base.joinpath('categorical-encoding')\n",
    "sys.path.append(str(catenc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification problem\n",
    "\n",
    "For Binary classifier we will work with the example 10.2 of T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical Learning Ed. 2\", Springer, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_split = 8379\n",
    "rs_enc = 1179\n",
    "rs_rf = 5991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2, make_classification\n",
    "X_h, y_h = make_classification(n_samples = 1011, n_features=10, n_informative=5, n_redundant=0, \n",
    "                               class_sep = 0.01, random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now convert the last column to the categorical\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "disczr1 = KBinsDiscretizer(n_bins=20, encode='ordinal', strategy='uniform')\n",
    "cat_column1 = disczr1.fit_transform(X_h[:,-1].reshape(-1, 1)) * 193 % 20 #We want to break the monotonicity\n",
    "disczr2 = KBinsDiscretizer(n_bins=15, encode='ordinal', strategy='uniform')\n",
    "cat_column2 = disczr2.fit_transform(X_h[:,-2].reshape(-1, 1)) * 173 % 20 #We want to break the monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207933</td>\n",
       "      <td>1.525917</td>\n",
       "      <td>0.527136</td>\n",
       "      <td>-1.295324</td>\n",
       "      <td>-0.381380</td>\n",
       "      <td>-0.577176</td>\n",
       "      <td>-1.053963</td>\n",
       "      <td>-0.002429</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592509</td>\n",
       "      <td>0.066990</td>\n",
       "      <td>1.748452</td>\n",
       "      <td>0.277453</td>\n",
       "      <td>3.791661</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>-0.416096</td>\n",
       "      <td>-0.149276</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.653129</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>-0.121440</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>-1.266728</td>\n",
       "      <td>-0.462035</td>\n",
       "      <td>-2.071419</td>\n",
       "      <td>1.237412</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0  0.207933  1.525917  0.527136 -1.295324 -0.381380 -0.577176 -1.053963   \n",
       "1  0.592509  0.066990  1.748452  0.277453  3.791661 -1.369970 -0.416096   \n",
       "2 -0.653129  0.268849 -0.121440  0.020929 -1.266728 -0.462035 -2.071419   \n",
       "\n",
       "      col_7  cat1  cat2  \n",
       "0 -0.002429  17.0  18.0  \n",
       "1 -0.149276  16.0   5.0  \n",
       "2  1.237412   5.0   4.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = pd.DataFrame(X_h[:, 0:-2], columns=[f'col_{i}' for i in range(8)])\n",
    "predictors['cat1'] = cat_column1\n",
    "predictors['cat2'] = cat_column2\n",
    "#predictors['cat1_orig'] = cat_column1\n",
    "#predictors['cat2_orig'] = cat_column2\n",
    "predictors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h[y_h<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=rs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6534653465346535\n",
      "Test accuracy:  0.5665024630541872\n",
      "AUC:  0.5957240038872692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, max_features=3, min_samples_leaf=1,\n",
    "                               random_state=rs_rf, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))\n",
    "print('AUC: ', roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09049425, 0.09231747, 0.16752997, 0.18313366, 0.08708329,\n",
       "       0.14120372, 0.07879025, 0.08120745, 0.04244824, 0.0357917 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, Now we will try to use the probabilistic target encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "We really should use cross-validation to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the target encoding model\n",
    "\n",
    "First we will train a model using target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.630):\n",
      "{'loo__sigma': 0.1, 'rf__max_depth': 20, 'rf__max_features': 3, 'rf__min_samples_leaf': 1}\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "\n",
    "loo = LeaveOneOutEncoder(cols=['cat1', 'cat2'], sigma=0.05, random_state=2834)\n",
    "rf = RandomForestClassifier(n_estimators=400, random_state=2834, n_jobs=-1) \n",
    "pipe = Pipeline(steps=[('loo',loo), ('rf',rf)])\n",
    "\n",
    "param_grid = {\n",
    "    'loo__sigma': [0.01, 0.05, 0.1, 0.2],\n",
    "    'rf__max_depth': [20,30,40],\n",
    "    'rf__max_features' : [1,2,3],\n",
    "    'rf__min_samples_leaf': [1,2,3]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1,)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7044334975369458\n"
     ]
    }
   ],
   "source": [
    "test_predict = search.best_estimator_.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the probabilistic encoder\n",
    "\n",
    "First we create a class that makes it easier for us to run sklearn cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.posterior_imputation_bc import PosteriorImputationEncoderBC  \n",
    "from category_encoders.pte_utils import EncoderWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.670):\n",
      "{'classifier__max_depth': 30, 'classifier__max_features': 4, 'classifier__min_samples_leaf': 1, 'encoder__leave_one_out': False, 'encoder__n_draws': 4, 'encoder__prior_samples_ratio': 0.001}\n",
      "Wall time: 7min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pte = PosteriorImputationEncoderBC(cols=['cat1', 'cat2'], n_draws=5, random_state=2834, prior_samples_ratio=0)\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=30, max_features=1, \n",
    "                               random_state=2834, n_jobs=-1) \n",
    "wrapper_model = EncoderWrapper(pte, model)\n",
    "\n",
    "param_grid = {\n",
    "    'encoder__leave_one_out': [False, True],\n",
    "    'encoder__n_draws': [4,5],\n",
    "    'encoder__prior_samples_ratio': [0, 1E-3],\n",
    "    'classifier__max_depth': [30,40],\n",
    "    'classifier__max_features' : [3,4],\n",
    "    'classifier__min_samples_leaf': [1,2]\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "\n",
    "search = GridSearchCV(wrapper_model, param_grid, cv=5, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7192118226600985\n"
     ]
    }
   ],
   "source": [
    "test_predict = search.best_estimator_.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, test_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
