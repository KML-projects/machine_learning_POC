{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81  k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53  k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 378 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('train.csv.zip')\n",
    "all_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicate or constant columns as per https://www.kaggle.com/yohanb/categorical-features-encoding-xgb-0-554\n",
    "columns_to_remove = ['X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293', 'X297', 'X330', 'X347', \n",
    "                     'X382', 'X232', 'X279', 'X35', 'X37', 'X39', 'X302', 'X113', 'X134', 'X147', 'X222', \n",
    "                     'X102', 'X214', 'X239', 'X76', 'X324', 'X248', 'X253', 'X385', 'X172', 'X216', 'X213', \n",
    "                     'X84', 'X244', 'X122', 'X243', 'X320', 'X245', 'X94', 'X242', 'X199', 'X119', 'X227', \n",
    "                     'X146', 'X226', 'X326', 'X360', 'X262', 'X266', 'X247', 'X254', 'X364', 'X365', 'X296', 'X299',\n",
    "                     'X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293', 'X297', 'X330', 'X347']\n",
    "new_columns = [col for col in all_data.columns if col not in columns_to_remove]\n",
    "data1 = all_data[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 321)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline linear regression without categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.iloc[:,10:].values\n",
    "y = data1.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.5843533315823948\n",
      "Test R^2:  -6.160078533586281e+22\n",
      "Test MSE:  9.528489855981273e+24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Train R^2: ', model.score(X_train, y_train))\n",
    "print('Test R^2: ', r2_score(y_test, preds))\n",
    "print('Test MSE: ', mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding of all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, OrdinalEncoder\n",
    "test_data = pd.read_csv('test.csv.zip')\n",
    "combined = pd.concat([all_data, test_data], axis=0, sort=False)\n",
    "\n",
    "cat_column_names = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_column_names:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(combined[col])\n",
    "    label_encoders[col] = label_encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean encoding of columns\n",
    "Now we will do a naive mean encoding of the categorical columns X0-X8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pathlib\n",
    "current = pathlib.Path(os.getcwd())\n",
    "base = current.parent.parent\n",
    "catenc = base.joinpath('categorical-encoding')\n",
    "sys.path.append(str(catenc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.5753189141790043\n",
      "Test R^2:  0.5875966381290332\n",
      "Test MSE:  63.79109014170886\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "cat_column_names = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']\n",
    "\n",
    "for col in cat_column_names:\n",
    "    data2[col] = label_encoders[col].transform(data2[col])\n",
    "\n",
    "\n",
    "X = data2.iloc[:,2:].values\n",
    "y = data2.iloc[:,1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)\n",
    "\n",
    "mean_enc_columns = [data2.columns.get_loc(c) for c in data2.columns if c in cat_column_names]\n",
    "\n",
    "\n",
    "m_encoder = LeaveOneOutEncoder(cols=mean_enc_columns)\n",
    "m_encoder.fit(X_train, y_train)\n",
    "X_train = m_encoder.transform(X_train)\n",
    "X_test = m_encoder.transform(X_test)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha = 20) #Best alpha we could get via hyperparameter tuning\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Train R^2: ', model.score(X_train, y_train))\n",
    "print('Test R^2: ', r2_score(y_test, preds))\n",
    "print('Test MSE: ', mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.5647513986247792\n",
      "Test R^2:  0.5838897210695404\n",
      "Test MSE:  64.36448090946871\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)\n",
    "\n",
    "m_encoder = LeaveOneOutEncoder(cols=mean_enc_columns)\n",
    "m_encoder.fit(X_train, y_train)\n",
    "X_train = m_encoder.transform(X_train)\n",
    "X_test = m_encoder.transform(X_test)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha=55)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Train R^2: ', model.score(X_train, y_train))\n",
    "print('Test R^2: ', r2_score(y_test, preds))\n",
    "print('Test MSE: ', mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is actually worse. Is it because we ignored the standard deviation?\n",
    "\n",
    "We will try to achieve the best result by using random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.6028315218920661\n",
      "Test R^2:  0.6168638369298607\n",
      "Test MSE:  59.264001641680935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)\n",
    "\n",
    "\n",
    "#m_encoder = LeaveOneOutEncoder(cols=mean_enc_columns)\n",
    "m_encoder = TargetEncoder(cols=mean_enc_columns, smoothing=1E-2)\n",
    "m_encoder.fit(X_train, y_train)\n",
    "X_train = m_encoder.transform(X_train)\n",
    "X_test = m_encoder.transform(X_test)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=300, max_depth=5, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print('Train R^2: ', model.score(X_train, y_train))\n",
    "print('Test R^2: ', r2_score(y_test, preds))\n",
    "print('Test MSE: ', mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate submission\n",
    "kaggle1 = test_data[new_columns[2:]].copy()\n",
    "\n",
    "for col in cat_column_names:\n",
    "    kaggle1[col] = label_encoders[col].transform(kaggle1[col])\n",
    "    \n",
    "X_kaggle = kaggle1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_tran = m_encoder.transform(X_kaggle)\n",
    "preds_kaggle = model.predict(X_kaggle_tran)\n",
    "preds_kaggle_df = pd.DataFrame({'ID': test_data.ID, 'y': preds_kaggle, })\n",
    "preds_kaggle_df.head(2)\n",
    "preds_kaggle_df.to_csv('te_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better than Ridge regression, but without limiting the max depth it overfits tremendously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.5896616280903844\n",
      "Test R^2:  0.6134296855602425\n",
      "Test MSE:  59.79520065661073\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.posterior_imputation import PosteriorImputationEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)\n",
    "\n",
    "\n",
    "m_encoder = PosteriorImputationEncoder(cols=mean_enc_columns, n_draws=25, prior_samples_ratio=0.01, random_state=2834)\n",
    "m_encoder.fit(X_train, y_train)\n",
    "X_train = m_encoder.transform(X_train)\n",
    "X_test = m_encoder.transform(X_test)\n",
    "y_train = m_encoder.expand_y(y_train)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=300, max_depth=5, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "preds = m_encoder.average_y(preds)\n",
    "\n",
    "print('Train R^2: ', model.score(X_train, y_train))\n",
    "print('Test R^2: ', r2_score(y_test, preds))\n",
    "print('Test MSE: ', mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not see much difference. We need another example where we can prove better effectiveness of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_tran = m_encoder.transform(X_kaggle)\n",
    "preds_kaggle = model.predict(X_kaggle_tran)\n",
    "preds_kaggle = m_encoder.average_y(preds_kaggle)\n",
    "preds_kaggle_df = pd.DataFrame({'ID': test_data.ID, 'y': preds_kaggle, })\n",
    "preds_kaggle_df.head(2)\n",
    "preds_kaggle_df.to_csv('pm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "We will do cross-validation to ensure validity of comparison between the two approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_enc_column_names = [c for c in data2.columns if c in cat_column_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one out encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.518):\n",
      "{'loo__sigma': 0.05, 'rf__max_depth': 40, 'rf__max_features': 4, 'rf__min_samples_leaf': 1}\n",
      "Test MSE:  0.5624305944520647\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "\n",
    "loo = LeaveOneOutEncoder(cols=mean_enc_column_names,  random_state=2834)\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=2834, n_jobs=-1) \n",
    "pipe = Pipeline(steps=[('loo',loo), ('rf',rf)])\n",
    "\n",
    "param_grid = {\n",
    "    'loo__sigma': [0.01, 0.05, 0.1],\n",
    "    'rf__max_depth': [20,30,40],\n",
    "    'rf__max_features' : [3,4],\n",
    "    'rf__min_samples_leaf': [1,2]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=data1.columns[2:])\n",
    "X_test = pd.DataFrame(X_test, columns=data1.columns[2:])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1,scoring='r2')\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "test_predict = search.best_estimator_.predict(X_test)\n",
    "print('Test R^2: ', r2_score(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael.larionov\\AppData\\Local\\Continuum\\anaconda3\\envs\\cat_enc\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.529):\n",
      "{'encoder__n_draws': 3, 'encoder__prior_samples_ratio': 0.001, 'regressor__max_depth': 20, 'regressor__max_features': 6, 'regressor__min_samples_leaf': 2}\n",
      "Test R^2:  0.5677487531068137\n",
      "Wall time: 50min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%autoreload 2\n",
    "from category_encoders.pte_utils import EncoderWrapperR\n",
    "\n",
    "pte = PosteriorImputationEncoder(cols=mean_enc_column_names, random_state=2834)\n",
    "model = RandomForestRegressor(n_estimators=400, random_state=2834, n_jobs=-1) \n",
    "wrapper_model = EncoderWrapperR(pte, model)\n",
    "\n",
    "param_grid = {\n",
    "    #'encoder__leave_one_out': [False, True],\n",
    "    'encoder__n_draws': [2,3,4],\n",
    "    'encoder__prior_samples_ratio': [1E-5, 1E-4, 1E-3],\n",
    "    'regressor__max_depth': [15,20,30],\n",
    "    'regressor__max_features' : [4,5,6],\n",
    "    'regressor__min_samples_leaf': [1,2,3]\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=data1.columns[2:])\n",
    "X_test = pd.DataFrame(X_test, columns=data1.columns[2:])\n",
    "\n",
    "search = GridSearchCV(wrapper_model, param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "test_predict = search.best_estimator_.predict(X_test)\n",
    "print('Test R^2: ', r2_score(y_test, test_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
