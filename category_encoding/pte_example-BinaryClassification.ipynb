{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pathlib\n",
    "current = pathlib.Path(os.getcwd())\n",
    "base = current.parent.parent\n",
    "catenc = base.joinpath('categorical-encoding')\n",
    "sys.path.append(str(catenc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification problem\n",
    "\n",
    "For Binary classifier we will work with the example 10.2 of T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical Learning Ed. 2\", Springer, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "X_h, y_h = make_hastie_10_2(random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now convert the last column to the categorical\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "disczr1 = KBinsDiscretizer(n_bins=20, encode='ordinal', )\n",
    "cat_column1 = disczr1.fit_transform(X_h[:,-1].reshape(-1, 1)) * 193 % 20 #We want to break the monotonicity\n",
    "disczr2 = KBinsDiscretizer(n_bins=15, encode='ordinal', )\n",
    "cat_column2 = disczr2.fit_transform(X_h[:,-2].reshape(-1, 1)) * 173 % 20 #We want to break the monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.372591</td>\n",
       "      <td>-2.090973</td>\n",
       "      <td>1.708557</td>\n",
       "      <td>-0.275200</td>\n",
       "      <td>-0.398902</td>\n",
       "      <td>1.024470</td>\n",
       "      <td>-0.765034</td>\n",
       "      <td>-0.189323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.469180</td>\n",
       "      <td>1.482655</td>\n",
       "      <td>0.573892</td>\n",
       "      <td>1.517456</td>\n",
       "      <td>-0.036815</td>\n",
       "      <td>-0.188150</td>\n",
       "      <td>-0.654887</td>\n",
       "      <td>1.071954</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.405521</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>-1.036971</td>\n",
       "      <td>-0.901881</td>\n",
       "      <td>-2.526267</td>\n",
       "      <td>0.429153</td>\n",
       "      <td>-1.177047</td>\n",
       "      <td>-0.425995</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0 -1.372591 -2.090973  1.708557 -0.275200 -0.398902  1.024470 -0.765034   \n",
       "1  0.469180  1.482655  0.573892  1.517456 -0.036815 -0.188150 -0.654887   \n",
       "2 -0.405521  0.231156 -1.036971 -0.901881 -2.526267  0.429153 -1.177047   \n",
       "\n",
       "      col_7  cat1  cat2  \n",
       "0 -0.189323   5.0  10.0  \n",
       "1  1.071954  11.0  18.0  \n",
       "2 -0.425995  11.0   4.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = pd.DataFrame(X_h[:, 0:-2], columns=[f'col_{i}' for i in range(8)])\n",
    "predictors['cat1'] = cat_column1\n",
    "predictors['cat2'] = cat_column2\n",
    "predictors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_h[y_h<0] = 0\n",
    "y_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9766666666666667\n",
      "Test accuracy:  0.8654166666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=20, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9864583333333333\n",
      "Test accuracy:  0.88625\n"
     ]
    }
   ],
   "source": [
    "#Now we will try to do target encoding\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "loo = LeaveOneOutEncoder(cols=['cat1', 'cat2'], random_state=2834)\n",
    "loo.fit(pd.DataFrame(X_train, columns=predictors.columns), y_train)\n",
    "X_train = loo.transform(pd.DataFrame(X_train, columns=predictors.columns))\n",
    "X_test = loo.transform(pd.DataFrame(X_test, columns=predictors.columns))\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=17, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, Now we will try to use the probabilistic target encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  1.0\n",
      "Test accuracy:  0.8291666666666667\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "from category_encoders.multiple_imputation_bc import ProbabilisticTargetEncoderForBinaryClassification \n",
    "#The class name is really long LOL\n",
    "pte = ProbabilisticTargetEncoderForBinaryClassification(cols=['cat1', 'cat2'], n_draws=25, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "pte.fit(X_train, y_train)\n",
    "X_train = pte.transform(X_train, is_train=True)\n",
    "X_test = pte.transform(X_test, is_train=True)\n",
    "y_train = pte.expand_y(y_train)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=30, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "#preds = pte.predict(X_test, model)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "preds = pte.average_y(preds)\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy sucks. But we don't have to sample during the prediction, we can just predict for both 0 and 1 and then take the average based on the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.99455\n",
      "Test accuracy:  0.8304166666666667\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors.values, y_h, test_size=0.2, random_state=2834)\n",
    "from category_encoders.multiple_imputation_bc import ProbabilisticTargetEncoderForBinaryClassification \n",
    "#The class name is really long LOL\n",
    "\n",
    "pte = ProbabilisticTargetEncoderForBinaryClassification(cols=['cat1', 'cat2'], n_draws=50, random_state=2834)\n",
    "X_train = pd.DataFrame(X_train, columns=predictors.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=predictors.columns)\n",
    "pte.fit(X_train, y_train)\n",
    "X_train = pte.transform(X_train, is_train=True)\n",
    "X_test = pte.transform(X_test, is_train=False)\n",
    "y_train = pte.expand_y(y_train)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, max_depth=30, random_state=2834, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "preds = pte.predict(X_test, lambda XX: model.predict_proba(XX)[:,1])\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(y_test, preds.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
